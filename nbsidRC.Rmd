---
title: 'Challenge: Prediction de la consommation electrique sur l''ile d''Ouessant'
author: "Cedric Bezy, Riwan Mouster (SIdRC)"
output:
  html_notebook:
    depth: 4
    toc: yes
  pdf_document:
    toc: yes
---

\tableofcontents

# Présentation et contexte
Nous sommes étudiants en Master _Statistique et Informatique Décisionnelle_ à Toulouse. Afin d'améliorer nos compétences en Machine Learning, nous participons de temps en temps à des compétitions de type _Kaggle_, ou autres.

Dans ce cadre, nous avons choisi de participer au _"Data Challenge"_ organisé par le "groupe des Jeunes Statisticien.ne.s". Ce projet consiste à prévoir la consommation électrique de l’île d'Ouessant pendant 8 jours, à chaque heure. Pour cela, nous disposons des fichiers suivants :

* **conso_train**: un an de données de consommation historiques, à la maille horaire
* **meteo_train**: un an de données météorologiques à la maille tri-horaire, issues de la proche station météorologique de Brest
* **meteo_pred**: une semaine de données météorologiques à la maille tri-horaire, issues de la même station et faisant office de prédiction météorologique. Dans ce projet, on considèrera ces prédictions comme étant exactes.
* **sample_submission**: l'exemple de fichier-type pour la soumission, à la maille horaire sur les 8 jours de prédiction.

Pour répondre aux attentes de ce projet, nous avons utilisé le logiciel R. Ce notebook décrit notre démarche ainsi que le code utilisé pendant ce projet.

# Résumé

Notre démarche générale est la suivante :

1. Import des packages / données
2. Nettoyage des données
3. Création de nouvelles variables à partir des données
4. Statistique Descriptive
5. Modélisation et Prédiction

Les points 3, 4 et 5 sont itératifs, afin d'améliorer la prédiction. 

Pour la prédiction, nous avons utilisé notamment *randomForest* et *xgboost*. La meilleure prédiction à été trouvée grâce à **xgboost**.

# Mise en place de l'environnement

Avant de démarrer l'explication de la démarche, il est utile que le lecteur dispose du même environnement (chemin, packages, ...)

### Langue de l'environnement

Nous avons fais le choix de travailler dans un enviromment local anglais (notamment pour les dates).

```{r, echo=TRUE, include=TRUE, message=FALSE}
# Set Option : Date in English
Sys.setlocale("LC_TIME", "English_United States")
```

### Installation des packages

Ces lignes de code permettent d'installer les packages nécessaires.

```{r, echo=TRUE, include=TRUE, message=FALSE}
# install.packages(c("dplyr", "tidyr"))
# install.packages(c("ggplot2", "ggpubr"))
# install.packages(c("circular", "lubridate", "magrittr"))
# install.packages(c("xgboost", "FactoMineR", "gsubfn"))
```

### Importation des packages

Maintenant que les packages sont installés, importons-les dans l'environnement.

```{r, message=FALSE}
## Gestion DataFrames
library(dplyr)
library(tidyr)

## Plots
library(ggplot2)
library(ggpubr)

## Gestion des types particuliers (angle et dates)
library(circular)
library(lubridate)
library(magrittr)

## Table disjonctive
library(FactoMineR)

## XGboost
library(xgboost)

## Simplification des résultats de fonctions en listes
library(gsubfn)

```


# Fonctions

Les fonctions suivantes ont été programmées et utilisées pendant le projet.

### Fonctions de mesure d'écart entre deux vecteurs

Dans ce projet, nos résultats seront évalués selon les critères _"Mean Absolute Percentage Error"_ (**MAPE**), et _"Root Mean Square Error"_ (**RMSE**). Il existe certes des packages donnant ces fonctions, mais les programmer par nous même nous permettra de mieux comprendre ces critères - en plus d'éviter à avoir à charger d'autres packages.

```{r}
## Fonction mape
MAPE <- function(y_pred, y_true){
    mape <- mean(abs((y_true - y_pred)/y_true))
    return(mape)
}
## Fonction RMSE
RMSE <- function(x, y){
    rmse <- sqrt(mean((x - y) ^ 2))
    return(rmse)
}
```

### Fonctions Descriptives: Voir les données manquantes par variable

```{r plot_na}
# count_na compte le nombre de valeurs manquantes dans un vecteur x
count_na <- function(x){
    sum(is.na(x))
}

# prop_na donne la proportion de valeurs manquantes dans un vecteur x
prop_na <- function(x){
    mean(is.na(x))
}

#------------------------
# plotting missing values
#------------------------
# plot_na renvoie le diagramme en barre donnant la proportion de valeurs
#   manquantes (NA) dans chaque colonne d'une data.frame.
# En entrée:
#   "df": data.frame à évaluer
#   pareto: logical
#       si TRUE, les barres sont ordonnées par ordre décroissant
#       si FALSE, alors les barres sont rangées par ordre alphabetique
#   simplify: logical
#       si TRUE, les colonnes sans valeurs manquantes ne sont pas affichés,
#           seules restent les variables avec valeurs manquantes
#       si FALSE, toutes les variables sont affichées
#   legend:  logical ; = TRUE si la legende doit etre affichee, =FALSE sinon
#   maintitle : titre du graphique (voir "label" de l fonction ggtitle)
#   subtitle : soustitre du graphique (voir la fonction ggtitle)
# En sortie :
#   un graphique de type ggplot

plot_na <- function(
    df,
    pareto = TRUE,
    simplify = TRUE,
    legend = FALSE,
    maintitle = "Missing Values",
    subtitle = NULL
){
    ## data : proportion of na
    dfna <- data.frame(
        variable = colnames(df),
        nb_na = sapply(df, count_na),
        p_na = sapply(df, prop_na)
    )
    if(simplify){
        dfna <- dfna %>% dplyr::filter(nb_na >= 1)
    }
    if(pareto){
        dfna <- dfna %>% dplyr::arrange(desc(p_na), variable)
        dfna$variable <- factor(dfna$variable, unique(dfna$variable))
    }
    ## Plot Layers
    resbarplot <- ggplot(data = dfna) +
        geom_bar(
            mapping = aes(variable, p_na, fill = p_na),
            stat = "identity",
            col = "black"
        )
    resbarplot <- resbarplot +
        ## modify x axis
        scale_x_discrete(name = NULL) +
        # modify y axis
        scale_y_continuous(
            name = "Prop NA",
            breaks = seq(0, 1, 0.1),
            limits = c(0, 1)
        ) +
        ## Modify colors
        scale_fill_continuous(name="Prop NA", high="#333333", low="#CCCCCC")
    
    ## set title abnd theme
    resbarplot <- resbarplot +
        ggtitle(maintitle, subtitle) +
        theme_bw()
    
    ## delete legend
    if(!legend){
        resbarplot <- resbarplot + guides(fill = FALSE)
    }
    ## results
    return(resbarplot)
}
```

### Fonction pour diviser une table de données en deux échantillons.

```{r train_test_split}
# La fonction permet de spliter une data.frame en 2 echantillon selon une proportion ptrain entre 0 et 1.
# L'échantillon train contient une proportion ptrain de lignes
# l'échantillon test contient une proportion (1-ptrain) de lignes
# En sortie : une liste de deux data.frames "train"" et "test""

train_test_split <- function(data, ptrain = 0.75)
{
    N <- nrow(data)
    n <- floor(ptrain * N)
    s <- sample.int(N, n, replace = FALSE)
    reslist <- list(
        train = data[s,],
        test = data[-s,]
    )
    return(reslist)
}
```

### Fonction pour traiter les variables numériques

Comment doivent être traitées les variables numériques ? En général, les valeurs manquantes sont remplacées par la moyenne de la variable dans l'échantillon d'apprentissage (train). Enfin, les variables peuvent être centrées et / ou réduites. Nous avons créé une fonction qui permettait de le faire, par niveau ou non.

Dans l'échantillon test, le remplacement des variables se fait sur le modèle de la table d'apprentissage (valeur de la moyenne et de l'écart-type).

Par niveau, cela signifie que la table est divisée en plusieurs morceaux selon des facteurs, le remplacement des valeurs manquantes et centrer / réduire se fait dans chaque morceau indépendamment des autres.

```{r replace_na_center_scale}
## function to replace na in a vector x, and center and scale if needed
## this function :
##      replace na by mean into x, center and scale x
##      then, it applies on y with x values

replace_na_center_scale <- function(x, y = NULL,
                                    na_replace = TRUE,
                                    center = TRUE,
                                    scale = TRUE)
{
    moy <- mean(x, na.rm = TRUE)
    if(na_replace){x <- replace(x, is.na(x), moy)}
    std <- sd(x, na.rm = TRUE)
    cent <- ifelse(center & !is.na(moy), moy, FALSE)
    scal <- ifelse(scale & !is.na(std) & std != 0, std, FALSE)
    x_scaled <- scale(x, cent, scal)[,1]
    ## Do the same on y, with x values
    if(length(y > 0)){
        if(na_replace){y <- replace(y, is.na(y), moy)}
        y_scaled <- scale(y, cent, scal)[,1]
        result <- list(x = x_scaled, y = y_scaled)
    }else{
        result <- x_scaled
    }
    return(result)
}
```

```{r deal_train_test_numerics}
# cette fonction fait appel à "replace_na_center_scale" ci-dessus

# En entrée:
# train and test: deux data.frames
# variables : liste des colonnes à traiter
# by: liste des facteurs de division
# na_replace,  center, scale : logicals

# En sortie : une liste de taille 3:
#   - train : nouvelle table d'apprentissage
#   - test : nouvelle table de test
#   - columns : correspond aux variables effectivement modifiées

deal_train_test_numerics <- function(
    train,
    test,
    variables,
    by = NULL,
    na_replace = TRUE,
    center = TRUE,
    scale = TRUE
){
    numerics <- names(which(sapply(train[variables], is.numeric)))
    if(length(numerics) >= 1){
        ## keep only wished values to have the same structure
        train$DATA_ <- "train"
        train$ORDER_ <- 1:nrow(train)
        test$DATA_ <- "test"
        test$ORDER_ <- 1:nrow(test)
        all_variables <- c(numerics, by, "DATA_", "ORDER_")
        subTrain <- train[all_variables]
        subTest <- test[all_variables]
        ## Then, subTrain and subTest have the same structure
        # bind train and test data
        alldata <- rbind(subTrain, subTest)
        alldata$ORDER_ <- 1:nrow(alldata)
        
        # make a list of subdata
        if(length(by) >= 1){
            alldata_ls <- split(alldata, alldata[by])
        }else{
            alldata_ls <- list(alldata)
        }
        ## function to apply on each data.frame (see "replace_na_center_scale")
        ## return a new data frame with arrangeddata
        .repl_scale_vars <- function(df){
            ok <- (df$DATA_ == 'train')
            scaled <- mapply(
                replace_na_center_scale,
                x = df[which(ok), numerics],
                y = df[which(!ok), numerics],
                na_replace = na_replace,
                center = center,
                scale = scale
            )
            if(any(!ok)){
                scaled <- bind_rows(apply(scaled, 1, bind_cols))
            }
            others <- setdiff(colnames(df), numerics)
            resDf <- cbind(df[others], scaled)
            return(resDf)
        }
        # applying .repl_scale_numerics on each subdata
        arrangedDf <- bind_rows(lapply(alldata_ls, .repl_scale_vars))
        
        # then, we can rebuild train and test
        arrangedTrain <- arrangedDf %>%
            dplyr::filter(DATA_ == "train") %>%
            dplyr::arrange(ORDER_)
        train[numerics] <- arrangedTrain[numerics]
        train$DATA_ <- NULL
        train$ORDER_ <- NULL
        
        arrangedTest <- arrangedDf %>%
            dplyr::filter(DATA_ == "test") %>%
            dplyr::arrange(ORDER_) %>%
            dplyr::mutate(DATA_ = NULL, ORDER_ = NULL)
        test[numerics] <- arrangedTest[numerics]
        test$DATA_ <- NULL
        test$ORDER_ <- NULL
        
        ## result list : train / test
        resLs <- list(train = train, test = test, columns = numerics)
    }else{
        resLs <- list(train = train, test = test, columns = NULL)
    }
    return(resLs)
}
```

### Fonction pour transformer des facteurs en variables disjonctives

Nous avons également programmé une fonction permettant de remplacer les facteurs en variables disjonctives (1 ou 0), afin de pouvoir les traiter comme des variables numériques.

```{r deal_train_test_factors}
# cette fonction fait appel à "tab.disjonctif" du package FactoMineR

# En entrée:
# train and test: deux data.frames
# variables : liste des colonnes à transformer
# remove : = TRUE si les variables de bases sont à supprimer, = FALSe sinon

# En sortie : une liste de taille 3:
#   - train : nouvelle table d'apprentissage
#   - test : nouvelle table de test
#   - columns : correspond aux noms des nouvelles colonnes

deal_train_test_factors <- function(train, test, variables, remove = TRUE, ...)
{
    if(length(variables) >= 1){
        tabTrain <- FactoMineR::tab.disjonctif(train[variables])
        tabTest <- FactoMineR::tab.disjonctif(test[variables])
        columns <- unname(colnames(tabTrain))
        if(remove){
            train <- train[setdiff(colnames(train), variables)]
            test <- test[setdiff(colnames(test), variables)]
        }
        train <- cbind(train, tabTrain)
        test <- cbind(test, tabTest)
    }else{
        columns <- NULL
    }
    reslist <- list(train = train, test = test, columns = columns)
}
```


# Gestion des Données

Maintenant que l'environnement de travail a été initialisé, nous pouvons nous occuper des données

### Chemin d'accès aux données

_path\_file_ contient une chaine donnant le dossier de localisation des fichiers de données.

```{r}
## A modifier
path_files <- "ouessant_copy/data" 
```

### Importation des données

```{r}
# Importation de conso_train
conso_train <- read.csv2(
    file = sprintf("%s/conso_train.csv", path_files),
    dec = ".",
    stringsAsFactors = FALSE
)

## Importation de meteo_train
meteo_train <- read.csv2(
    file = sprintf("%s/meteo_train.csv", path_files),
    dec = ".",
    stringsAsFactors = FALSE
)

## Importation de meteo_prev
meteo_prev <- read.csv2(
    file = sprintf("%s/meteo_prev.csv", path_files),
    dec = ".",
    stringsAsFactors = FALSE
)
```

Un problème rencontré au cours de l'import est que R ne reconnait pas l'encodage des noms de colonnes. Aussi avons-nous renommé les colonnes afin de faciliter l'utilisation des méthodes de machine learning.

```{r}
colnames(conso_train)
colnames(meteo_train)
```

```{r}
## rename conso_train
colnames(conso_train) <- c('datetime', 'puissance')

## rename meteo_train
newnames <- c(
    "datetime", "temp", "pression", "hr", "p_rosee",
    "visi", "vt_moy", "vt_raf", "vt_dir", "rr_3h",
    "neige", "nebul"
)
colnames(meteo_train) <- newnames
colnames(meteo_prev) <- newnames
```

### Description des données

Les données météo sont décrites comme suit :

* **datetime**: dates des observations (sera convertie en Date)
* **temp** : température (°C)
* **pression** : pression (hPa)
* **hr** : hmidité relative (%), mesure la quantité de vapeur d'eau présente dans l'air
* **p_rosee** : point de rosée (°C)
* **visi** : visibilité (km)
* **vt_moy** : vitesse moyen du vent (km/h)
* **vt_raf** : vitesse des rafales de vent (km/h)
* **vt_dir** : direction du vent (degrés, de 0 à 359)
* **rr_3h** : précipitations sur 3h (mm)
* **neige** : neige (cm)
* **nebul** : nébulosité, ou couverture nuageuse (octats)

```{r}
summary(conso_train)
summary(meteo_train)
summary(meteo_prev)
```

### Nettoyage des données : suppression des doublons

L'étape suivante de la gestion des données consiste à nettoyer les données avant tout. C'est-à-dire de supprimer les lignes présentes plusieurs fois, et convertir les colonnes au bon format. "Le nettoyage des données est la base d'une bonne prédiction."

```{r}
## supprimer les doublons dans conso_train
dup_conso <- which(duplicated(conso_train))
conso_train <- conso_train[-dup_conso,]
print(sprintf("conso_train : %i lignes supprimées !", length(dup_conso)))

## supprimer les doublons dans meteo_train
dup_meteo <- which(duplicated(meteo_train))
meteo_train <- meteo_train[-dup_meteo,]
print(sprintf("meteo_train : %i lignes supprimées !", length(dup_meteo)))
```

### Formattage des variables

Dans la table _conso\_train_, la date doit être formatée, afin d'être convertie en date - sous R, il s'agit du type _"POSIXt"_. Nous conserverons également le fuseau horaire.

De plus, certaines puissances sont données aux temps hh:59:59 à chaque heure. Considérant la seconde négligeable dans notre échelle de travail, et pour le besoin de l'étude, nous avons décidé d'arrondir ces dates à l'heure (soit une seconde plus tard).

```{r}
## extraire la date
conso_dt <- strsplit(conso_train$datetime, split = "\\+")

## Extraire la date
conso_dt_format <- as.POSIXct(strptime(
    sapply(conso_dt, function(x){x[1]}),
    format = "%Y-%m-%dT%H:%M:%S"
))

## Enfin, on arrondit la date
conso_train$datetime <- round_date(conso_dt_format, "hour")
## fuseau horaire
conso_train$fuseau <- paste0("+", sapply(conso_dt, function(x){x[2]}))
```

Dans les tables _meteo\_train_ et _meteo\_prev_, nous devons également gérer les dates, mais pas seulement. En effet, la variable _vt\_dir_ est une variable circulaire : un vent de direction 350 et 10 degrés sont proches, et pourtant le vent moyen donnerait un vent en direction contraire (180 degrés).

```{r}
## dans meteo train
dt_meteotrain <- as.POSIXct(strptime(
    meteo_train$datetime,
    format = "%d/%m/%y %Hh%M"
))
meteo_train <- meteo_train %>%
    dplyr::mutate(
        datetime = dt_meteotrain,
        vt_dir = circular(vt_dir, type = "direction", units = "degrees", zero = 0)
    )

## dans meteo pred
dt_meteoprev <- as.POSIXct(strptime(
    meteo_prev$datetime,
    format = "%d/%m/%y %Hh%M"
))
meteo_prev <- meteo_prev  %>%
    dplyr::mutate(
        datetime = dt_meteoprev,
        vt_dir = circular(vt_dir, type = "direction", units = "degrees", zero = 0)
    )

```

### Création de variables

A partir des données, nous avons créé d'autres variables explicatives, dont certaines dérivées de la dates.

* **Weekday** : jour de la semaine ("Monday", ..., "Sunday")
* **Day**: jour dans le mois
* **Month**: mois de l'année ("January", ..., "December")
* **Year**: année
* **Hour**: heure dans la journée

En outre, nous avons établis d'autres facteurs:

* **rose_vt**: faire une moyenne sur la direction du vent n'a concrètement aucun sens. Nous avons donc décidé de découper cette variable en plusieurs classes, selon la rose de direction :
    + *North*: vent venant du nord (315 degrés ou +, ou en dessous de 45 degrés).
    + *East*: vent venant de l'est (entre 45 et 134.9 degrés)
    + *South*: vent venant du Sud (entre 135 et 224.9 degrés)
    + *West*: vent venant de l'Ouest (entre 255 et 314.9 degrés)
    
* **f_weekend**: =1 si Weekday = "Saturday" ou "Sunday", =0 sinon.
* **f_season**: ="summer" entre les mois d'Avril à Octobre, et "winter" entre les mois de Novembre à Mars
* **f_evening**: Cette variable permet de mettre l'accent sur les pics de fin de journée, en général lorsque les individus consomment le plus d'électricité:
    + en été ("summer"), =1 au dessus de 21h, =0 sinon.
    + en hiver ("winter"), =1 au dessus de 18h, =0 sinon

```{r}
meteo_train <- meteo_train %>%
    dplyr::mutate(
        Weekday = wday(datetime, label = TRUE, abbr = FALSE),
        Day = day(datetime),
        Month = month(datetime, label = TRUE, abbr = FALSE),
        Year = year(datetime),
        Hour = hour(datetime),
        rose_vt = cut(
            replace(vt_dir, vt_dir >= 315, 0),
            breaks = c(0, seq(45, 315, by = 90)),
            labels = c("North", "East", "South", "West"),
            right = FALSE
        ),
        f_weekend = Weekday %in% c("Saturday", "Sunday"),
        f_season = factor(
            ifelse(month(datetime) %in% c(4:10), "summer", "winter"),
            levels = c("summer", "winter")
        ),
        f_evening = as.numeric(
            ifelse(month(datetime) %in% c(4:10), Hour >= 21, Hour >= 18)
        )
    )

str(meteo_train)

meteo_prev <- meteo_prev %>%
    dplyr::mutate(
        Weekday = wday(datetime, label = TRUE, abbr = FALSE),
        Day = day(datetime),
        Month = month(datetime, label = TRUE, abbr = FALSE),
        Year = year(datetime),
        Hour = hour(datetime),
        rose_vt = cut(
            replace(vt_dir, vt_dir >= 315, 0),
            breaks = c(0, seq(45, 315, by = 90)),
            labels = c("North", "East", "South", "West"),
            right = FALSE
        ),
        f_weekend = Weekday %in% c("Saturday", "Sunday"),
        f_season = factor(
            ifelse(month(datetime) %in% c(4:10), "summer", "winter"),
            levels = c("summer", "winter")
        ),
        f_evening = as.numeric(
            ifelse(month(datetime) %in% c(4:10), Hour >= 21, Hour >= 18)
        )
    )

str(meteo_prev)

```




Nous avons à présent nos données.

# Statistique Descriptive

Avant tout, il est recommandé de faire des statistiques descriptives.

```{r, echo=FALSE, include=TRUE}

ggarrange(
    plot_na(meteo_train, subtitle = "Meteo Train") +
        theme(axis.text.x = element_text(angle = 30)),
    plot_na(meteo_prev, subtitle = "Meteo Prev") +
        theme(axis.text.x = element_text(angle = 30)),
    nrow = 1,
    ncol = 2,
    widths = c(8, 3)
) 

```

```{r, echo=FALSE, include=TRUE}

dfconso <- conso_train %>%
    dplyr::arrange(datetime) %>%
    dplyr::mutate(
        Weekday = wday(datetime, label = TRUE, abbr = TRUE),
        Day = day(datetime),
        Month = month(datetime, label = TRUE, abbr = TRUE),
        Year = year(datetime),
        Hour = hour(datetime),
        year_month = paste(Year, Month, sep = "-"),
        year_month = factor(year_month, unique(year_month))
    )

dfconso_summa_month <- dfconso %>%
    dplyr::group_by(Month, Hour) %>%
    dplyr::summarise(
        n = n(),
        moy_puiss = mean(puissance),
        std_puiss = sd(puissance)
    )

plot_conso_month_hour <- ggplot(
    data = dfconso_summa_month,
    mapping = aes(x = Hour, y = moy_puiss, col = Month)
) +
    geom_point() +
    geom_line() +
    scale_x_continuous(
        name = "Hour",
        breaks = seq(0, 23, 2)
    ) +
    scale_color_hue(name = 'Day', h.start = 100, direction = -1) +
    ggtitle("Consommation d'electricite moyenne par mois et par heure")

print(plot_conso_month_hour)


dfconso_summa_year_month <- dfconso %>%
    dplyr::group_by(year_month, Month, Hour) %>%
    dplyr::summarise(
        n = n(),
        moy_puiss = mean(puissance),
        std_puiss = sd(puissance)
    )

plot_conso_year_month_hour <- ggplot(
    data = dfconso_summa_year_month,
    mapping = aes(x = Hour, y = moy_puiss, col = Month)
) +
    geom_point() +
    geom_line() +
    facet_wrap(~year_month, scales = "free_x", nrow = 3) +
    scale_x_continuous(
        name = "Hour",
        breaks = seq(0, 23, 2)
    ) +
    scale_color_hue(name = 'Day', h.start = 100, direction = -1) +
    ggtitle("Consommation d'electricite moyenne par mois et par heure")

print(plot_conso_year_month_hour)

```

```{r, echo=FALSE, include=TRUE}
build_plot_train <- function(ivar){
    ggplot(data = meteo_train) +
        facet_wrap(~Year+Month, scales = "free_x", nrow = 3) +
        geom_line(
            mapping = aes_string('Day', ivar, col = 'as.factor(Hour)'),
            na.rm = TRUE
        ) +
        scale_color_hue(name = 'Hour', h.start = 100, direction = -1) +
        ggtitle(sprintf("%s selon mois et heure (train)", ivar))
}

build_plot_test <- function(ivar){
    ggplot(data = meteo_prev) +
        geom_line(
            mapping = aes_string('Hour', ivar, col = 'as.factor(Day)'),
            na.rm = TRUE
        ) +
        scale_color_hue(name = 'Day', h.start = 100, direction = -1) +
        ggtitle(sprintf("%s selon mois et heure (test)", ivar))
}

x_vars <- c(
    "temp", "pression", "hr",  "p_rosee", "visi",
    "vt_moy", "vt_raf", "rr_3h", "nebul"
)

plot_list_train <- lapply(
    x_vars,
    build_plot_train
)
names(plot_list_train) <- x_vars
plot_list_train

plot_list_test <- lapply(
    x_vars,
    build_plot_test
)
names(plot_list_test) <- x_vars
plot_list_test

```





# Mise en place du modèle

### Comment prédire une maille horaire en ayant des données météo en maille tri-horaire ?

Nous avons divisé la pression en 3 vecteurs :

* P0 contient la consommation aux heures H, ayant la météo donnée.
* P1 contient la consommation aux heures H + 1.
* P2 contient la consommation aux heures H + 2

Nous avons calculé 2 autres vecteurs :
* DP1 = P1 - P0 (écart entre les vecteurs P0 et P1)
* DP2 = P2 - P0 (écart entre les vecteurs P0 et P2)

Nous effectuerons 3 prédictions, sur les vecteurs P0, DP1 et DP2.


### Comment gérer le changement d'heure ?

Les données sont effectivement impactées par le changement d'heure, les derniers dimanches des mois d'octobre et mars.

En octobre, on recule d'une heure, mais dans les données, il n'y a pas deux lignes à 2h du matin. Avec les données à disposition, ce n'est donc pas un problème.

En mars, on avance d'une heure. Il y a donc une valeur de moins, puisqu'il n'y a pas de ligne à 2h du matin. Par conséquent, le modèle H+2 aura donc une ligne de moins.

```{r}
# consoDf : contains consommation :
#   - puissance P0 for each 3 hours.
#   - puissance variation for each 3 hours + 1 (DP1 = P1 - P0)
#   - puissance variation for each 3 hours + 2 (DP1 = P1 - P0)

consoDf <- conso_train %>%
    dplyr::select(datetime, puissance) %>%
    ## on détermine les heures H, H+1 et H+2
    dplyr::mutate(
        R3 = hour(datetime) %% 3,
        vpuiss = factor(R3, levels = 0:2, labels = paste0("P", 0:2)),
        datetime = datetime - 3600 * R3,
        R3 = NULL
    ) %>%
    ## on distribue les puissances en 3 colonnes P0, P1 et P2
    tidyr::spread(vpuiss, puissance) %>%
    dplyr::filter(!is.na(P0)) %>%
    dplyr::mutate(
        DP1 = P1 - P0,
        DP2 = P2 - P0
    )

str(consoDf)
```

### Quelles variables ont été retenues dans le modèle final ?





### Comment gérer les valeurs manquantes ?

Les valeurs manquantes ont été remplacées par la moyenne par mois et par heure (toutes les 3heures, donc), ce afin de risquer de biaiser l'étude. En effet, la température n'est pas la même le 1er janvier à midi qu'à minuit, et encore moins que le 1er juillet.

### Quid du centrage et de la réduction d'échelle ?

Nous avons également centré réduit en fonction du mois et de l'heure.









